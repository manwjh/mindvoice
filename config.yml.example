# macOS 语音桌面助手配置文件示例
# 复制此文件为 config.yml 并填入你的配置信息
# 注意：config.yml 包含敏感信息，已添加到 .gitignore

# ASR 配置（火山引擎）
asr:
  base_url: wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_async  # 双向流式优化版本（推荐）
  # 其他可选版本：
  # - bigmodel: 双向流式普通版本（每包输入对应每包返回）
  # - bigmodel_nostream: 流式输入模式（准确率更高，延迟较大）
  app_id: ""  # 请填入你的 app_id
  app_key: ""  # 请填入你的 app_key
  access_key: ""  # 请填入你的 access_key
  language: zh-CN  # 识别语言：zh-CN（中文）或 en-US（英语）
  enable_nonstream: true  # 二遍识别：双向流式实时返回 + 非流式重新识别分句片段（快+准，仅限 bigmodel_async）
  max_connection_duration: 5400  # 最大单次连接时长（秒），默认5400秒（90分钟）
  # 说明：
  # - 火山引擎ASR服务有单次连接时长限制（通常1-2小时）
  # - 为避免被动断连，系统会在达到此时长前主动停止录音
  # - 停止后会通知用户可以重新开始录音
  # - 建议值：5400秒（90分钟）= 1.5小时，留有安全边界
  # - 适用场景：长时间会议、演讲、课程录制等

# LLM 配置（大语言模型）
llm:
  provider: perfxcloud-专线  # 服务提供商
  api_key: ""  # 请填入你的 API Key
  base_url: https://deepseek.perfxlab.cn/v1  # API 基础 URL
  model: openai/Qwen3-Next-80B-Instruct  # 模型名称（使用 openai/ 前缀以支持自定义 OpenAI 兼容端点）
  max_context_tokens: 128000  # 最大上下文长度

# 存储配置
storage:
  # 数据根目录（支持 ~ 展开为用户主目录）
  # 
  # 推荐的跨平台路径：
  # - macOS:   ~/Library/Application Support/MindVoice
  # - Linux:   ~/.local/share/MindVoice
  # - Windows: %APPDATA%\MindVoice  (通常是 C:\Users\用户名\AppData\Roaming\MindVoice)
  # - iOS:     ~/Documents/MindVoice
  # - Android: /data/data/com.mindvoice.app/files/MindVoice
  # 
  # 简单方案（桌面平台通用）：
  # - data_dir: ~/MindVoice  (在用户主目录下创建 MindVoice 文件夹)
  #
  # 当前默认为 macOS 路径，其他平台请根据上述推荐修改
  # 或使用 scripts/init_config.py 自动生成适合当前平台的配置
  data_dir: ~/Library/Application Support/MindVoice
  
  database: database/history.db    # 数据库文件路径（相对于 data_dir）
  images: images                   # 图片存储目录（相对于 data_dir）
  knowledge: knowledge             # 知识库存储目录（相对于 data_dir）
  backups: backups                 # 备份文件目录（相对于 data_dir）
  
  # 最终的完整路径示例：
  # - 数据库: {data_dir}/database/history.db
  # - 图片: {data_dir}/images/*.png
  # - 知识库: {data_dir}/knowledge/chroma/
  # - 备份: {data_dir}/backups/*.db.backup

# 音频配置
audio:
  format: WAV  # 音频格式
  channels: 1  # 声道数（1=单声道，2=立体声）
  rate: 16000  # 采样率（Hz）
  chunk: 3200  # 每次读取的帧数（3200帧 = 200ms，符合火山引擎推荐的最优性能配置）
  # 说明：火山引擎建议单包音频大小为100~200ms，200ms性能最优
  # 计算公式：chunk = rate × 时长（秒）
  # - 200ms: 16000 × 0.2 = 3200帧（推荐）
  # - 100ms: 16000 × 0.1 = 1600帧
  
  # 缓冲区管理
  max_buffer_seconds: 60  # 最大缓冲时长（秒），超过后自动清理旧数据（避免长时间录音内存溢出）
  # 说明：
  # - 对于长时间录音（如1小时演讲），音频数据会累积到几百MB
  # - 设置缓冲区上限后，超过限制会自动清理旧数据，只保留最近的音频
  # - 实时ASR不受影响，音频数据已通过流式发送给ASR服务
  # - 16kHz单声道：60秒约1.92MB，120秒约3.84MB
  # - 建议值：60秒（1分钟）- 120秒（2分钟）
  
  # 音频处理（WebRTC Audio Processing Module）
  audio_processing:
    enabled: true  # 是否启用音频处理（推荐开启）
    # 说明：音频处理包括AGC（自动增益控制）和NS（噪声抑制）
    # 作用：
    # 1. 标准化音频音量，提升VAD准确性
    # 2. 过滤背景噪音，提升识别清晰度
    # 3. 适应不同麦克风和环境
    
    enable_agc: true  # 自动增益控制（Automatic Gain Control）
    # 作用：自动调整音频音量到目标水平
    # 适用场景：
    # - 麦克风音量不稳定
    # - 说话声音时大时小
    # - 麦克风距离不固定
    # 效果：提升VAD准确性，改善ASR识别率
    
    enable_ns: true  # 噪声抑制（Noise Suppression）
    # 作用：过滤背景噪音，保留语音信号
    # 适用场景：
    # - 有背景噪音的环境（风扇、空调等）
    # - 键盘打字声
    # - 远场拾音
    # 效果：减少背景噪音干扰，提升语音清晰度
    
    agc_level: 2  # AGC级别 (0-3，数字越大增益调整越强，推荐2)
    # 0: 最小增益调整
    # 1: 轻度调整
    # 2: 中等调整（推荐，适合大多数场景）
    # 3: 最大调整（强烈增益，可能引入失真）
    
    ns_level: 2  # NS级别 (0-3，数字越大噪声抑制越强，推荐2)
    # 0: 不抑制噪音
    # 1: 轻度抑制
    # 2: 中等抑制（推荐，平衡噪音和语音质量）
    # 3: 最大抑制（可能影响语音自然度）
    
    # 音频处理流程：
    # 原始音频 → AGC (音量标准化) → NS (噪声过滤) → VAD (语音检测) → ASR (识别)
    
    # 性能影响：
    # - WebRTC APM（原生实现）: CPU占用约1-2%，延迟<10ms
    # - 简化版（Python实现）: CPU占用约3-5%，延迟<20ms
    # 注意：如果安装 webrtc-audio-processing 失败，会自动回退到简化版

  
  # VAD配置（语音活动检测，用于过滤静音，节约ASR成本）
  vad:
    enabled: false  # 是否启用VAD（默认关闭，向后兼容）
    library: "webrtcvad"  # VAD库：webrtcvad
    mode: 2  # WebRTC VAD敏感度：0-3，越高越严格（0=最宽松，3=最严格，推荐1-2）
    frame_duration_ms: 20  # VAD检测帧长度：10/20/30ms（推荐20ms）
    
    # 检测阈值（控制启停灵敏度和延迟）
    speech_start_threshold: 2       # 连续N帧检测到语音才启动ASR（建议2-5）
    # 延迟权衡：
    # - threshold=2: 启动延迟~40ms，更快响应，可能误触发
    # - threshold=5: 启动延迟~100ms，更准确，略有延迟感
    
    speech_end_threshold: 10        # 连续M帧静音才停止ASR（建议8-15）
    # 说明：值太小会频繁启停，值太大会延长ASR运行时间
    
    min_speech_duration_ms: 1000     # 最小语音时长（毫秒），过滤短噪音
    
    # 缓冲机制（防止截断，补偿延迟）
    pre_speech_padding_ms: 100      # 语音开始前缓冲（保留开头100ms）
    # 重要：即使VAD延迟100ms才启动ASR，前置缓冲保证不丢失开头音节
    
    post_speech_padding_ms: 300     # 语音结束后缓冲（保留结尾300ms）
  
  # VAD 延迟说明：
  # 1. 首次语音延迟分析：
  #    - VAD检测: ~20ms/帧 × 1帧 = 20ms
  #    - 状态确认: 20ms × speech_start_threshold
  #    - ASR启动: ~10ms（已连接）或 ~200ms（新连接）
  #    - 总延迟: threshold=2时约60ms，threshold=5时约130ms
  # 
  # 2. 持续语音延迟：
  #    - VAD处理: <0.1ms（纯内存操作，WebRTC VAD极快）
  #    - 几乎无感知延迟
  # 
  # 3. 前置缓冲补偿：
  #    - 即使VAD延迟100ms，前置缓冲保证开头不丢失
  #    - 用户说"你好"，"你"字不会被截断
  # 
  # 4. 推荐配置：
  #    - 成本优先: threshold=5, mode=3 (节约60%，延迟130ms)
  #    - 体验优先: threshold=2, mode=1 (节约40%，延迟60ms)
  #    - 零延迟: enabled=false (无节约，无延迟)
  #
  # VAD成本节约说明：
  # - 启用VAD可以过滤60-80%的静音音频，预计节约40-60%的ASR成本
  # - mode参数：0最宽松（可能误检），3最严格（可能漏检），1-2为平衡值
  # - 静音时不发送任何数据，最大化成本节约
  # - 如果发现截断问题，可以调整：
  #   * 减小 speech_start_threshold（更快启动，但可能误触发）
  #   * 增大 speech_end_threshold（更晚停止，更完整但成本略高）
  #   * 增大 pre/post_speech_padding_ms（更多缓冲，更安全）

# UI 配置
ui:
  theme: light  # 主题：light 或 dark
  position:
    x: 100  # 窗口 X 坐标
    y: 100  # 窗口 Y 坐标
  size:
    width: 500  # 窗口宽度
    height: 400  # 窗口高度

# 日志配置
logging:
  level: WARNING  # 日志级别：DEBUG, INFO, WARNING, ERROR, CRITICAL
  console: true  # 是否输出到控制台
  file: true  # 是否输出到文件
  directory: logs  # 日志文件目录
  max_file_size_mb: 10  # 单个日志文件最大大小（MB）
  backup_count: 5  # 保留的日志文件数量
cleanup:
  enabled: true  # 是否启用自动清理
  interval_hours: 24  # 清理间隔（小时）
  log_retention_days: 7  # 日志保留天数
  orphan_images: true  # 是否清理孤儿图片
  format: "%(asctime)s | %(levelname)-8s | %(name)s | %(message)s"  # 日志格式
  date_format: "%Y-%m-%d %H:%M:%S"  # 时间格式
  
  # 分组件日志级别（可选，覆盖全局级别）
  components:
    ASR: INFO  # ASR服务日志级别
    LLM: INFO  # LLM服务日志级别
    AudioDevice: INFO  # 音频设备日志级别
    Network: INFO  # 网络相关日志级别
    Storage: INFO  # 存储相关日志级别

# 会员体系配置
membership:
  # 默认会员等级（永久有效）
  default_tier: free
  
  # 免费会员设置
  free_permanent: true  # 免费会员永久有效
  
  # 会员额度配置（单位：ASR为毫秒，LLM为tokens）
  quotas:
    free:
      asr_duration_ms_monthly: 3600000        # 1小时 = 60*60*1000ms
      llm_tokens_monthly: 100000               # 10万tokens
    vip:
      asr_duration_ms_monthly: 36000000       # 10小时
      llm_tokens_monthly: 1000000              # 100万tokens
    pro:
      asr_duration_ms_monthly: 180000000      # 50小时
      llm_tokens_monthly: 5000000              # 500万tokens
    pro_plus:
      asr_duration_ms_monthly: 720000000      # 200小时
      llm_tokens_monthly: 20000000             # 2000万tokens
  
  # 订阅周期配置
  subscription_periods:
    - months: 1
      name: "1个月"
      discount: 0
    - months: 3
      name: "3个月"
      discount: 0.1    # 9折
    - months: 6
      name: "6个月"
      discount: 0.15   # 85折
    - months: 12
      name: "年付"
      discount: 0.2    # 8折
  
  # 订阅周期限制
  period_limits:
    min_months: 1
    max_months: 120    # 最多10年
  
  # 过期提醒配置
  expiration_reminders:
    days_before: [7, 3, 1]
  
  # 自动降级配置
  auto_downgrade:
    enabled: true
    downgrade_to: free
    default_period: 1

# 用户信息配置
user_profile:
  # 头像配置
  avatar:
    max_size_mb: 5  # 最大文件大小（MB）
    allowed_formats: ['png', 'jpg', 'jpeg']  # 允许的格式
    storage_path: 'avatars'  # 存储目录（相对于data_dir）
  
  # 字段限制
  limits:
    nickname_max_length: 50
    bio_max_length: 500
    email_required: false  # 是否必填

# 模型配置
model:
  # 模型来源类型
  model_source_type: 'vendor'  # 'vendor' 或 'user'
  
  # 厂商提供的模型（计入会员额度）
  vendor_models:
    enabled: true
    default_model: 'gpt-4'
  
  # 用户自备模型（不计入会员额度）
  user_models:
    enabled: true
    allow_custom: true  # 是否允许用户配置自己的模型
    supported_providers:
      - openai
      - anthropic
      - deepseek
      - moonshot